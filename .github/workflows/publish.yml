name: Release

# This workflow performs comprehensive validation before releasing:
# 1. Full test suite including cross-language compatibility (Python â†” C++ â†” Java)
# 2. Security validation (Argon2 availability, PQ crypto, RAM detection)
# 3. Build binaries for Linux, Windows, macOS
# 4. Build Java JAR
# 5. Sign all artifacts with GPG
# 6. Generate SHA256/MD5 hashes
# 7. Submit to VirusTotal for scanning
# 8. Upload to GitHub Release with comprehensive results

on:
  release:
    types: [published]

jobs:
  light-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache liboqs
        id: cache-liboqs
        uses: actions/cache@v4
        with:
          path: /usr/local
          key: liboqs-0.11.0-${{ runner.os }}-${{ runner.arch }}

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake build-essential libssl-dev zlib1g-dev libargon2-dev liblzma-dev ffmpeg

      - name: Install liboqs
        run: |
          chmod +x .github/scripts/install-liboqs.sh
          .github/scripts/install-liboqs.sh

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Run comprehensive release test suite
        env:
          BASEFWX_OBFUSCATE: "1"
          ALLOW_BAKED_PUB: "0"
          BASEFWX_BENCH_RESULTS_DIR: results
          BASEFWX_RELEASE_TAG: ${{ github.ref_name }}
        run: |
          chmod +x scripts/test_all.sh
          # Run full test suite including cross-language compatibility
          ./scripts/test_all.sh --fbench
          
          echo "âœ… All tests passed"
          echo "Cross-language compatibility verified:"
          echo "  - Python â†” C++ encryption/decryption"
          echo "  - Python â†” Java encryption/decryption"
          echo "  - C++ â†” Java encryption/decryption"
          echo "  - fwxAES cross-language tests"
          echo "  - b512/pb512 cross-language tests"
          echo "  - Argon2 compatibility tests"

      - name: Verify live benchmark coverage
        run: |
          python3 - <<'PY'
          import json
          from pathlib import Path

          bench_path = Path("results/benchmarks-latest.json")
          if not bench_path.exists():
              raise SystemExit("Missing results/benchmarks-latest.json")

          data = json.loads(bench_path.read_text(encoding="utf-8"))
          labels = {entry.get("label") for entry in data.get("tests", [])}
          required = {"fwxaes_live_py_total", "kfae_py_total"}
          missing = sorted(label for label in required if label not in labels)
          if missing:
              raise SystemExit(f"Missing benchmark labels: {', '.join(missing)}")
          print("Live benchmark coverage OK:", ", ".join(sorted(required)))
          PY

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            results/benchmarks-*.json
            results/benchmarks-*.txt
          if-no-files-found: error

      - name: Install Python package for security validation
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install -e './python[argon2]'
      
      - name: Security validation
        env:
          PYTHONPATH: ${{ github.workspace }}/python
        run: |
          echo "ðŸ”’ Running security validations..."
          
          # Verify Argon2 is available
          python3 << 'EOF'
          import basefwx
          if not basefwx.basefwx._ARGON2_AVAILABLE:
              print("âš ï¸  WARNING: Argon2 not available in Python")
              exit(1)
          print("âœ… Argon2 available in Python")
          
          # Check KDF default
          print(f"Default KDF: {basefwx.basefwx.USER_KDF_DEFAULT}")
          print(f"Current KDF: {basefwx.basefwx.USER_KDF}")
          
          # Verify RAM detection works
          ram = basefwx.basefwx._get_available_ram_mib()
          if ram:
              print(f"âœ… RAM detection working: {ram:.0f} MiB available")
          else:
              print("âš ï¸  RAM detection unavailable (will assume sufficient)")
          EOF
          
          echo "âœ… Security validation complete"

  build-cli-linux:
    runs-on: ${{ matrix.runner }}
    container:
      image: ${{ matrix.container_image }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - runner: ubuntu-latest
            container_image: debian:10
            arch: amd64
            output: basefwx-linux-amd64
          - runner: ubuntu-24.04-arm
            container_image: debian:10
            arch: arm64
            output: basefwx-linux-arm64
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache liboqs
        id: cache-liboqs
        uses: actions/cache@v4
        with:
          path: /usr/local
          key: liboqs-0.11.0-static-debian10-${{ runner.arch }}

      - name: Install system deps
        run: |
          set -euo pipefail
          if ! apt-get update; then
            if [ -f /etc/apt/sources.list ]; then
              sed -i 's|deb.debian.org/debian|archive.debian.org/debian|g' /etc/apt/sources.list || true
              sed -i 's|security.debian.org/debian-security|archive.debian.org/debian-security|g' /etc/apt/sources.list || true
            fi
            apt-get -o Acquire::Check-Valid-Until=false update
          fi
          apt-get install -y \
            build-essential \
            libssl-dev \
            zlib1g-dev \
            liblzma-dev \
            pkg-config \
            dpkg-dev \
            binutils \
            ca-certificates \
            wget \
            git
          # Debian 10 package naming for Argon2 may vary by suite/mirror.
          if ! apt-get install -y libargon2-dev; then
            apt-get install -y libargon2-0-dev
          fi

      - name: Install modern CMake
        run: |
          set -euo pipefail
          arch="$(uname -m)"
          case "$arch" in
            x86_64) cmake_arch="x86_64" ;;
            aarch64|arm64) cmake_arch="aarch64" ;;
            *)
              echo "Unsupported architecture for CMake bootstrap: $arch" >&2
              exit 1
              ;;
          esac
          cmake_ver="3.30.5"
          url="https://github.com/Kitware/CMake/releases/download/v${cmake_ver}/cmake-${cmake_ver}-linux-${cmake_arch}.tar.gz"
          wget -qO /tmp/cmake.tgz "$url"
          tar -xzf /tmp/cmake.tgz -C /tmp
          cp -r "/tmp/cmake-${cmake_ver}-linux-${cmake_arch}/"* /usr/local/
          cmake --version

      - name: Install liboqs
        run: |
          chmod +x .github/scripts/install-liboqs.sh
          export LIBOQS_USE_APT=0
          export LIBOQS_BUILD_SHARED=OFF
          .github/scripts/install-liboqs.sh

      - name: Verify static liboqs
        run: |
          test -f /usr/local/include/oqs/oqs.h
          test -f /usr/local/lib/liboqs.a

      - name: Configure
        run: |
          set -euo pipefail
          multiarch="$(dpkg-architecture -qDEB_HOST_MULTIARCH)"
          libdir="/usr/lib/${multiarch}"
          for dep in \
            "${libdir}/libcrypto.a" \
            "${libdir}/libssl.a" \
            "${libdir}/libz.a" \
            "${libdir}/libargon2.a" \
            "${libdir}/liblzma.a" \
            "/usr/local/lib/liboqs.a"; do
            if [ ! -f "$dep" ]; then
              echo "Missing static dependency: $dep" >&2
              exit 1
            fi
          done
          cmake -S cpp -B cpp/build \
            -DCMAKE_BUILD_TYPE=Release \
            -DBASEFWX_REQUIRE_ARGON2=ON \
            -DBASEFWX_REQUIRE_OQS=ON \
            -DBASEFWX_REQUIRE_LZMA=ON \
            -DBASEFWX_OQS_STATIC=ON \
            -DOPENSSL_USE_STATIC_LIBS=TRUE \
            -DOPENSSL_CRYPTO_LIBRARY="${libdir}/libcrypto.a" \
            -DOPENSSL_SSL_LIBRARY="${libdir}/libssl.a" \
            -DOQS_INCLUDE_DIR=/usr/local/include \
            -DOQS_LIBRARY=/usr/local/lib/liboqs.a \
            -DZLIB_LIBRARY="${libdir}/libz.a" \
            -DZLIB_INCLUDE_DIR=/usr/include \
            -DARGON2_LIBRARY="${libdir}/libargon2.a" \
            -DARGON2_INCLUDE_DIR=/usr/include \
            -DLZMA_LIBRARY="${libdir}/liblzma.a" \
            -DLZMA_INCLUDE_DIR=/usr/include \
            -DBASEFWX_NATIVE_OPT=OFF \
            -DCMAKE_CXX_FLAGS="-Wno-deprecated-declarations"

      - name: Build
        run: cmake --build cpp/build --config Release

      - name: Verify static crypto/PQ linkage
        run: |
          deps="$(readelf -d cpp/build/basefwx_cpp)"
          printf '%s\n' "$deps"
          if printf '%s\n' "$deps" | grep -Eq 'liboqs\.so|libcrypto\.so|libssl\.so'; then
            echo "Binary still links against dynamic OQS/OpenSSL" >&2
            exit 1
          fi

      - name: Strip
        run: |
          mkdir -p dist
          cp cpp/build/basefwx_cpp "dist/${{ matrix.output }}"
          strip "dist/${{ matrix.output }}"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.output }}
          path: dist/${{ matrix.output }}
          if-no-files-found: error

  linux-compat-smoke:
    runs-on: ubuntu-latest
    needs: [build-cli-linux]
    continue-on-error: ${{ matrix.allow_failure }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - debian: "9"
            allow_failure: true
          - debian: "10"
            allow_failure: false
          - debian: "11"
            allow_failure: false
          - debian: "12"
            allow_failure: false
          - debian: "13"
            allow_failure: false
    container:
      image: debian:${{ matrix.debian }}
    permissions:
      contents: read
    steps:
      - name: Install runtime deps
        run: |
          set -euo pipefail
          if ! apt-get update; then
            if [ -f /etc/apt/sources.list ]; then
              sed -i 's|deb.debian.org/debian|archive.debian.org/debian|g' /etc/apt/sources.list || true
              sed -i 's|security.debian.org/debian-security|archive.debian.org/debian-security|g' /etc/apt/sources.list || true
            fi
            apt-get -o Acquire::Check-Valid-Until=false update
          fi
          apt-get install -y ca-certificates libstdc++6 zlib1g liblzma5
          if ! apt-get install -y libargon2-1; then
            apt-get install -y libargon2-0 || true
          fi

      - name: Download Linux amd64 artifact
        uses: actions/download-artifact@v4
        with:
          name: basefwx-linux-amd64
          path: dist

      - name: Smoke run
        run: |
          set -euo pipefail
          chmod +x dist/basefwx-linux-amd64
          out="$(dist/basefwx-linux-amd64 hash512 "debian-${{ matrix.debian }}")"
          if [ "${#out}" -ne 128 ]; then
            echo "Unexpected hash512 output length on Debian ${{ matrix.debian }}: ${#out}" >&2
            exit 1
          fi

  build-cli-windows:
    runs-on: windows-2022
    strategy:
      fail-fast: false
      matrix:
        include:
          - arch: amd64
            triplet: x64-windows-static
            cmake_arch: x64
            output: basefwx-windows-amd64.exe
          - arch: x86
            triplet: x86-windows-static
            cmake_arch: Win32
            output: basefwx-windows-x86.exe
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache vcpkg binaries
        uses: actions/cache@v4
        with:
          path: ${{ github.workspace }}\\vcpkg_binary_cache
          key: ${{ runner.os }}-${{ matrix.triplet }}-vcpkg-${{ hashFiles('cpp/vcpkg.json', 'cpp/vcpkg-configuration.json') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.triplet }}-vcpkg-
            ${{ runner.os }}-vcpkg-

      - name: Prepare vcpkg cache dir
        shell: pwsh
        run: |
          New-Item -ItemType Directory -Force "${{ github.workspace }}\\vcpkg_binary_cache" | Out-Null

      - name: Setup vcpkg
        uses: lukka/run-vcpkg@v11
        with:
          vcpkgDirectory: ${{ github.workspace }}\\vcpkg
          runVcpkgInstall: true
          vcpkgJsonGlob: "cpp/vcpkg.json"
          vcpkgConfigurationJsonGlob: "cpp/vcpkg-configuration.json"
          binaryCachePath: ${{ github.workspace }}\\vcpkg_binary_cache

      - name: Configure
        shell: pwsh
        env:
          VCPKG_MAX_CONCURRENCY: "8"
        run: |
          cmake -S cpp -B cpp/build `
            -G "Visual Studio 17 2022" `
            -A ${{ matrix.cmake_arch }} `
            -DCMAKE_TOOLCHAIN_FILE="${{ github.workspace }}\\vcpkg\\scripts\\buildsystems\\vcpkg.cmake" `
            -DVCPKG_TARGET_TRIPLET=${{ matrix.triplet }} `
            -DCMAKE_SYSTEM_VERSION=10.0 `
            -DBASEFWX_REQUIRE_ARGON2=ON `
            -DBASEFWX_REQUIRE_OQS=ON `
            -DBASEFWX_OQS_STATIC=ON `
            -DBASEFWX_WIN_IPO=OFF

      - name: Build
        shell: pwsh
        env:
          VCPKG_MAX_CONCURRENCY: "8"
        run: cmake --build cpp/build --config Release --parallel

      - name: Prepare binary
        shell: pwsh
        run: |
          New-Item -ItemType Directory -Force dist | Out-Null
          $bin = "cpp/build/Release/basefwx_cpp.exe"
          if (!(Test-Path $bin)) { $bin = "cpp/build/basefwx_cpp.exe" }
          if (!(Test-Path $bin)) { throw "basefwx_cpp.exe not found" }
          Copy-Item $bin "dist/${{ matrix.output }}"

      - name: Verify static crypto linkage (Windows)
        shell: pwsh
        run: |
          $bin = "dist/${{ matrix.output }}"
          $dumpbin = Get-Command dumpbin -ErrorAction SilentlyContinue
          if (-not $dumpbin) {
            Write-Host "dumpbin unavailable; skipping dependency check"
            exit 0
          }
          $deps = & dumpbin /nologo /dependents $bin | Out-String
          Write-Host $deps
          if ($deps -match '(?i)(libcrypto|libssl|oqs|argon2|zlib).*\\.dll') {
            throw "Binary still depends on dynamic crypto/compression DLLs"
          }

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: basefwx-windows-${{ matrix.arch }}
          path: dist/${{ matrix.output }}
          if-no-files-found: error

  build-cli-macos:
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - runner: macos-15-intel
            arch: amd64
            target_arch: x86_64
            output: basefwx-mac-amd64
          - runner: macos-14
            arch: arm64
            target_arch: arm64
            output: basefwx-mac-arm64
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          host_arch="$(uname -m)"
          if [ "$host_arch" != "${{ matrix.target_arch }}" ]; then
            echo "Runner arch mismatch: expected ${{ matrix.target_arch }}, got ${host_arch}"
            exit 1
          fi
          brew update
          brew install openssl@3 argon2 liboqs

      - name: Configure
        run: |
          brew_prefix="$(brew --prefix)"
          openssl_crypto_lib="${brew_prefix}/opt/openssl@3/lib/libcrypto.a"
          if [ ! -f "$openssl_crypto_lib" ]; then
            openssl_crypto_lib="${brew_prefix}/opt/openssl@3/lib/libcrypto.dylib"
          fi
          openssl_ssl_lib="${brew_prefix}/opt/openssl@3/lib/libssl.a"
          if [ ! -f "$openssl_ssl_lib" ]; then
            openssl_ssl_lib="${brew_prefix}/opt/openssl@3/lib/libssl.dylib"
          fi
          argon2_lib="${brew_prefix}/opt/argon2/lib/libargon2.a"
          if [ ! -f "$argon2_lib" ]; then
            argon2_lib="${brew_prefix}/opt/argon2/lib/libargon2.dylib"
          fi
          oqs_lib="${brew_prefix}/opt/liboqs/lib/liboqs.a"
          if [ ! -f "$oqs_lib" ]; then
            oqs_lib="${brew_prefix}/opt/liboqs/lib/liboqs.dylib"
          fi
          for dep in "$openssl_crypto_lib" "$openssl_ssl_lib" "$argon2_lib" "$oqs_lib"; do
            if [ ! -f "$dep" ]; then
              echo "Missing dependency library: $dep"
              exit 1
            fi
          done
          echo "Dependency architecture check:"
          for dep in "$openssl_crypto_lib" "$openssl_ssl_lib" "$argon2_lib" "$oqs_lib"; do
            dep_archs="$(lipo -archs "$dep")"
            echo "$dep => $dep_archs"
            if ! echo "$dep_archs" | grep -qw "${{ matrix.target_arch }}"; then
              echo "Architecture mismatch for $dep (expected ${{ matrix.target_arch }})"
              exit 1
            fi
          done
          cmake -S cpp -B cpp/build \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_OSX_ARCHITECTURES="${{ matrix.target_arch }}" \
            -DCMAKE_OSX_DEPLOYMENT_TARGET=11.0 \
            -DBASEFWX_REQUIRE_ARGON2=ON \
            -DBASEFWX_REQUIRE_OQS=ON \
            -DBASEFWX_OQS_STATIC=ON \
            -DBASEFWX_NATIVE_OPT=OFF \
            -DCMAKE_CXX_FLAGS="-Wno-deprecated-declarations" \
            -DOPENSSL_USE_STATIC_LIBS=TRUE \
            -DOPENSSL_ROOT_DIR="${brew_prefix}/opt/openssl@3" \
            -DOPENSSL_CRYPTO_LIBRARY="${openssl_crypto_lib}" \
            -DOPENSSL_SSL_LIBRARY="${openssl_ssl_lib}" \
            -DARGON2_INCLUDE_DIR="${brew_prefix}/opt/argon2/include" \
            -DARGON2_LIBRARY="${argon2_lib}" \
            -DOQS_INCLUDE_DIR="${brew_prefix}/opt/liboqs/include" \
            -DOQS_LIBRARY="${oqs_lib}"

      - name: Build
        run: cmake --build cpp/build --config Release

      - name: Verify output architecture
        run: |
          archs="$(lipo -archs cpp/build/basefwx_cpp)"
          echo "Built binary architectures: ${archs}"
          if ! echo "$archs" | grep -qw "${{ matrix.target_arch }}"; then
            echo "Unexpected output arch; expected ${{ matrix.target_arch }}"
            exit 1
          fi

      - name: Verify no dynamic third-party crypto deps (macOS)
        run: |
          deps="$(otool -L cpp/build/basefwx_cpp)"
          echo "$deps"
          if echo "$deps" | grep -Eq '(liboqs|libargon2|libcrypto|libssl)\.dylib'; then
            echo "Binary still links dynamic third-party crypto libs" >&2
            exit 1
          fi

      - name: Strip
        run: |
          mkdir -p dist
          cp cpp/build/basefwx_cpp "dist/${{ matrix.output }}"
          strip -x "dist/${{ matrix.output }}"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.output }}
          path: dist/${{ matrix.output }}
          if-no-files-found: error

  build-java-jar:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y gradle ffmpeg

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Build Java jar
        working-directory: java
        run: |
          gradle --no-daemon clean build

      - name: Collect jar
        run: |
          mkdir -p dist
          jar_file="java/build/libs/basefwx-java.jar"
          if [ ! -f "$jar_file" ]; then
            jar_file=$(find java/build/libs -maxdepth 1 -name "*.jar" | head -n1)
          fi
          if [ -z "$jar_file" ] || [ ! -f "$jar_file" ]; then
            echo "Jar not found"
            exit 1
          fi
          cp "$jar_file" dist/basefwx-java.jar

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: basefwx-java
          path: dist/basefwx-java.jar
          if-no-files-found: error

  publish-benchmarks:
    runs-on: ubuntu-latest
    needs: [light-tests]
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: bench-results

      - name: Publish benchmark results to DEV
        run: |
          set -euo pipefail
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git fetch --no-tags origin DEV
          git checkout -B DEV origin/DEV
          mkdir -p website/results
          cp -f bench-results/benchmarks-*.json website/results/
          cp -f bench-results/benchmarks-*.txt website/results/
          git add website/results/benchmarks-*.json website/results/benchmarks-*.txt
          if git diff --cached --quiet; then
            echo "No benchmark updates to publish."
            exit 0
          fi
          git commit -m "Add benchmark results for ${{ github.ref_name }}"
          git push origin HEAD:DEV

  sign-release:
    runs-on: ubuntu-latest
    needs: [light-tests, build-cli-linux, linux-compat-smoke, build-cli-windows, build-cli-macos, build-java-jar]
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: dist

      - name: Collect binaries
        run: |
          mkdir -p dist_out
          files=(
            "dist/basefwx-linux-amd64/basefwx-linux-amd64"
            "dist/basefwx-linux-arm64/basefwx-linux-arm64"
            "dist/basefwx-windows-amd64/basefwx-windows-amd64.exe"
            "dist/basefwx-windows-x86/basefwx-windows-x86.exe"
            "dist/basefwx-mac-amd64/basefwx-mac-amd64"
            "dist/basefwx-mac-arm64/basefwx-mac-arm64"
            "dist/basefwx-java/basefwx-java.jar"
          )
          for file in "${files[@]}"; do
            if [ ! -f "$file" ]; then
              echo "Missing artifact: $file"
              exit 1
            fi
            mv "$file" "dist_out/$(basename "$file")"
          done
          chmod +x \
            dist_out/basefwx-linux-amd64 \
            dist_out/basefwx-linux-arm64 \
            dist_out/basefwx-mac-amd64 \
            dist_out/basefwx-mac-arm64
          # Backward-compatible aliases for existing tooling/site links.
          cp dist_out/basefwx-linux-amd64 dist_out/basefwx-linux
          cp dist_out/basefwx-windows-amd64.exe dist_out/basefwx-windows.exe
          cp dist_out/basefwx-mac-arm64 dist_out/basefwx-mac
          chmod +x dist_out/basefwx-linux dist_out/basefwx-mac

      - name: Generate hashes
        run: |
          cd dist_out
          files=(
            "basefwx-linux-amd64"
            "basefwx-linux-arm64"
            "basefwx-windows-amd64.exe"
            "basefwx-windows-x86.exe"
            "basefwx-mac-amd64"
            "basefwx-mac-arm64"
            "basefwx-java.jar"
            "basefwx-linux"
            "basefwx-windows.exe"
            "basefwx-mac"
          )
          for file in "${files[@]}"; do
            sha256sum "$file" > "$file.sha256"
            md5sum "$file" > "$file.md5"
          done

      - name: Import GPG key
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
        run: |
          keyfile="$(mktemp)"
          printf '%s' "$GPG_PRIVATE_KEY" > "$keyfile"
          gpg --batch --import "$keyfile"
          rm -f "$keyfile"

      - name: Sign binaries
        env:
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
        run: |
          files=(
            "basefwx-linux-amd64"
            "basefwx-linux-arm64"
            "basefwx-windows-amd64.exe"
            "basefwx-windows-x86.exe"
            "basefwx-mac-amd64"
            "basefwx-mac-arm64"
            "basefwx-java.jar"
            "basefwx-linux"
            "basefwx-windows.exe"
            "basefwx-mac"
          )
          for file in "${files[@]}"; do
            gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" \
              --detach-sign -o "dist_out/${file}.sig" "dist_out/${file}"
          done

      - name: Verify signatures + hashes
        run: |
          files=(
            "basefwx-linux-amd64"
            "basefwx-linux-arm64"
            "basefwx-windows-amd64.exe"
            "basefwx-windows-x86.exe"
            "basefwx-mac-amd64"
            "basefwx-mac-arm64"
            "basefwx-java.jar"
            "basefwx-linux"
            "basefwx-windows.exe"
            "basefwx-mac"
          )
          for file in "${files[@]}"; do
            gpg --batch --verify "dist_out/${file}.sig" "dist_out/${file}"
          done
          cd dist_out
          for file in "${files[@]}"; do
            sha256sum -c "${file}.sha256"
            md5sum -c "${file}.md5"
          done

      - name: Upload release assets
        uses: softprops/action-gh-release@v2
        with:
          files: |
            dist_out/basefwx-*

      - name: VirusTotal scan
        env:
          VIRUSTOTAL_API_KEY: ${{ secrets.VIRUSTOTAL_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${VIRUSTOTAL_API_KEY:-}" ]; then
            echo "VIRUSTOTAL_API_KEY is not set"
            exit 1
          fi

          # Public VT API free tier is 4 requests/minute.
          # Enforce a strict 4 requests / 65s window.
          rate_limit_max=4
          rate_limit_window_sec=65
          rate_window_start=$(date +%s)
          rate_window_count=0
          vt_rate_limit_wait() {
            local now elapsed sleep_for
            now=$(date +%s)
            elapsed=$((now - rate_window_start))
            if [ "$elapsed" -ge "$rate_limit_window_sec" ]; then
              rate_window_start="$now"
              rate_window_count=0
              elapsed=0
            fi
            if [ "$rate_window_count" -ge "$rate_limit_max" ]; then
              sleep_for=$((rate_limit_window_sec - elapsed))
              if [ "$sleep_for" -gt 0 ]; then
                sleep "$sleep_for"
              fi
              rate_window_start=$(date +%s)
              rate_window_count=0
            fi
            rate_window_count=$((rate_window_count + 1))
          }
          vt_request() {
            local method="$1"
            local url="$2"
            shift 2
            local response http_code body

            vt_rate_limit_wait
            response=$(curl -sS -w "\n%{http_code}" --request "$method" "$url" "$@")
            http_code=$(printf '%s' "$response" | tail -n1)
            body=$(printf '%s' "$response" | sed '$d')

            if [ "$http_code" = "429" ]; then
              sleep 60
              vt_rate_limit_wait
              response=$(curl -sS -w "\n%{http_code}" --request "$method" "$url" "$@")
              http_code=$(printf '%s' "$response" | tail -n1)
              body=$(printf '%s' "$response" | sed '$d')
            fi

            if [ "$http_code" -lt 200 ] || [ "$http_code" -ge 300 ]; then
              echo "VirusTotal request failed ($http_code): $body" >&2
              return 1
            fi

            printf '%s' "$body"
          }

          tag="${GITHUB_REF_NAME}"
          repo="${GITHUB_REPOSITORY}"
          generated_at="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          json=$(jq -n --arg generated_at "$generated_at" --arg release_tag "$tag" --arg repository "$repo" \
            '{generated_at:$generated_at, release_tag:$release_tag, repository:$repository, files:[]}')
          allowlist_file=".github/virustotal-fp-allowlist.json"
          if [ -f "$allowlist_file" ]; then
            allowlist_json="$(cat "$allowlist_file")"
          else
            allowlist_json='{"rules":[]}'
          fi

          # Scan canonical release artifacts (all supported arches + Java JAR).
          files=(
            dist_out/basefwx-linux-amd64
            dist_out/basefwx-linux-arm64
            dist_out/basefwx-windows-amd64.exe
            dist_out/basefwx-windows-x86.exe
            dist_out/basefwx-mac-amd64
            dist_out/basefwx-mac-arm64
            dist_out/basefwx-java.jar
          )
          names=()
          ids=()
          statuses=()
          analyses=()

          for file in "${files[@]}"; do
            name="$(basename "$file")"
            echo "Submitting $name to VirusTotal..."
            submit=$(vt_request POST "https://www.virustotal.com/api/v3/files" \
              --header "accept: application/json" \
              --header "x-apikey: ${VIRUSTOTAL_API_KEY}" \
              --form file="@$file")
            analysis_id=$(echo "$submit" | jq -r '.data.id // empty')
            if [ -z "$analysis_id" ]; then
              echo "VirusTotal upload failed for $name: $submit"
              exit 1
            fi
            names+=("$name")
            ids+=("$analysis_id")
            statuses+=("queued")
            analyses+=("")
          done

          sleep 60

          # Poll analyses long enough to cover slower backends while
          # respecting the global request-rate guard.
          for attempt in $(seq 1 6); do
            pending=0
            for idx in "${!ids[@]}"; do
              if [ "${statuses[$idx]}" = "completed" ]; then
                continue
              fi
              analysis=$(vt_request GET "https://www.virustotal.com/api/v3/analyses/${ids[$idx]}" \
                --header "accept: application/json" \
                --header "x-apikey: ${VIRUSTOTAL_API_KEY}")
              status=$(echo "$analysis" | jq -r '.data.attributes.status // empty')
              analyses[$idx]="$analysis"
              statuses[$idx]="$status"
              if [ "$status" != "completed" ]; then
                pending=1
              fi
            done
            if [ "$pending" -eq 0 ]; then
              break
            fi
            sleep 60
          done

          for idx in "${!names[@]}"; do
            name="${names[$idx]}"
            analysis="${analyses[$idx]}"
            status="${statuses[$idx]}"
            file_info=""
            if [ -z "$analysis" ]; then
              analysis="{}"
            fi

            stats=$(echo "$analysis" | jq '.data.attributes.stats // {}')
            analysis_url=$(echo "$analysis" | jq -r '.data.links.self // empty')
            item_url=$(echo "$analysis" | jq -r '.data.links.item // empty')
            sha256=$(echo "$analysis" | jq -r '.meta.file_info.sha256 // empty')
            md5=$(echo "$analysis" | jq -r '.meta.file_info.md5 // empty')
            sha1=$(echo "$analysis" | jq -r '.meta.file_info.sha1 // empty')
            if [ "$status" != "completed" ] && [ -n "$sha256" ]; then
              # If analysis job is still queued, use the file endpoint's cached stats.
              file_info=$(vt_request GET "https://www.virustotal.com/api/v3/files/${sha256}" \
                --header "accept: application/json" \
                --header "x-apikey: ${VIRUSTOTAL_API_KEY}" || true)
              if [ -n "${file_info:-}" ]; then
                file_stats=$(echo "$file_info" | jq '.data.attributes.last_analysis_stats // {}')
                stats_total=$(echo "$file_stats" | jq '[.[]?] | add // 0')
                if [ "$stats_total" -gt 0 ]; then
                  stats="$file_stats"
                fi
                if [ -z "$md5" ]; then
                  md5=$(echo "$file_info" | jq -r '.data.attributes.md5 // empty')
                fi
                if [ -z "$sha1" ]; then
                  sha1=$(echo "$file_info" | jq -r '.data.attributes.sha1 // empty')
                fi
                if [ -z "$item_url" ]; then
                  item_url=$(echo "$file_info" | jq -r '.data.links.self // empty')
                fi
              fi
            fi
            engine_results=$(echo "$analysis" | jq '.data.attributes.results // {}')
            if [ -n "${file_info:-}" ]; then
              file_results=$(echo "$file_info" | jq '.data.attributes.last_analysis_results // {}')
              analysis_results_count=$(echo "$engine_results" | jq 'keys | length')
              if [ "$analysis_results_count" -eq 0 ]; then
                engine_results="$file_results"
              fi
            fi

            known_false_positives=$(jq -cn \
              --arg name "$name" \
              --argjson results "$engine_results" \
              --argjson allowlist "$allowlist_json" '
                [ $results
                  | to_entries[]
                  | . as $engine_entry
                  | ($engine_entry.key) as $engine_name
                  | ($engine_entry.value.result // "") as $result_name
                  | ($engine_entry.value.category // "") as $category
                  | select($category == "malicious" or $category == "suspicious")
                  | ($allowlist.rules // [])[]
                  | select((.engine // "") == $engine_name)
                  | select(($name | test((.file_regex // ".*"))))
                  | select(($result_name | test((.result_regex // ".*"); "i")))
                  | {
                      engine: $engine_name,
                      category: $category,
                      result: $result_name,
                      rule_id: (.id // ""),
                      reason: (.reason // "")
                    }
                ]
                | unique_by(.engine, .category, .result)')
            fp_malicious=$(echo "$known_false_positives" | jq '[.[] | select(.category=="malicious")] | length')
            fp_suspicious=$(echo "$known_false_positives" | jq '[.[] | select(.category=="suspicious")] | length')
            effective_stats=$(echo "$stats" | jq \
              --argjson fp_malicious "$fp_malicious" \
              --argjson fp_suspicious "$fp_suspicious" '
                .malicious = (((.malicious // 0) - $fp_malicious) | if . < 0 then 0 else . end)
                | .suspicious = (((.suspicious // 0) - $fp_suspicious) | if . < 0 then 0 else . end)')

            json=$(jq \
              --arg name "$name" \
              --arg analysis_id "${ids[$idx]}" \
              --arg analysis_url "$analysis_url" \
              --arg item_url "$item_url" \
              --arg sha256 "$sha256" \
              --arg md5 "$md5" \
              --arg sha1 "$sha1" \
              --arg status "$status" \
              --argjson stats "$stats" \
              --argjson effective_stats "$effective_stats" \
              --argjson known_false_positives "$known_false_positives" \
              '.files += [{
                name: $name,
                analysis_id: $analysis_id,
                analysis_url: $analysis_url,
                item_url: $item_url,
                sha256: $sha256,
                md5: $md5,
                sha1: $sha1,
                status: $status,
                stats: $stats,
                effective_stats: $effective_stats,
                known_false_positives: $known_false_positives
              }]' <<< "$json")
          done

          echo "$json" > dist_out/virustotal-results.json
          python python/tools/format_vt_results.py dist_out/virustotal-results.json dist_out/virustotal-results.txt
          cp dist_out/virustotal-results.txt dist_out/results.txt

      - name: Upload VirusTotal results
        uses: softprops/action-gh-release@v2
        with:
          files: |
            dist_out/virustotal-results.json
            dist_out/virustotal-results.txt
            dist_out/results.txt

      - name: Store VirusTotal results in repo
        continue-on-error: true
        env:
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
        run: |
          tag="${GITHUB_REF_NAME}"
          git fetch --no-tags origin DEV
          git checkout -B DEV origin/DEV
          mkdir -p website/results
          cp dist_out/virustotal-results.json "website/results/virustotal-${tag}.json"
          cp dist_out/virustotal-results.txt "website/results/virustotal-${tag}.txt"
          cp dist_out/virustotal-results.json website/results/virustotal-latest.json
          cp dist_out/virustotal-results.txt website/results/virustotal-latest.txt
          hash_files=(
            "basefwx-linux-amd64.sha256"
            "basefwx-linux-amd64.md5"
            "basefwx-linux-arm64.sha256"
            "basefwx-linux-arm64.md5"
            "basefwx-windows-amd64.exe.sha256"
            "basefwx-windows-amd64.exe.md5"
            "basefwx-windows-x86.exe.sha256"
            "basefwx-windows-x86.exe.md5"
            "basefwx-mac-amd64.sha256"
            "basefwx-mac-amd64.md5"
            "basefwx-mac-arm64.sha256"
            "basefwx-mac-arm64.md5"
            "basefwx-java.jar.sha256"
            "basefwx-java.jar.md5"
            "basefwx-linux.sha256"
            "basefwx-linux.md5"
            "basefwx-windows.exe.sha256"
            "basefwx-windows.exe.md5"
            "basefwx-mac.sha256"
            "basefwx-mac.md5"
          )
          for hash_file in "${hash_files[@]}"; do
            cp "dist_out/${hash_file}" "website/results/${hash_file}"
          done
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          key_id="$(gpg --list-secret-keys --with-colons | awk -F: '/^sec:/ {print $5; exit}')"
          if [ -z "$key_id" ]; then
            echo "No GPG signing key available"
            exit 1
          fi
          git config user.signingkey "$key_id"
          git config commit.gpgsign true
          cat > gpg-wrapper.sh <<'EOF'
          #!/usr/bin/env bash
          exec gpg --batch --yes --pinentry-mode loopback --passphrase "$GPG_PASSPHRASE" "$@"
          EOF
          chmod +x gpg-wrapper.sh
          git config gpg.program "$PWD/gpg-wrapper.sh"
          git add website/results/
          if git diff --cached --quiet; then
            echo "No results changes"
            exit 0
          fi
          git commit -m "chore: add VirusTotal results for ${tag}"
          git push origin HEAD:DEV

  publish-pypi:
    runs-on: ubuntu-latest
    needs: [sign-release, publish-benchmarks]
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          cd python
          pip install -e .
          pip install build cryptography pqcrypto numpy pillow argon2-cffi

      - name: Build package
        run: |
          cd python
          python -m build

      - name: Publish package
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: python/dist
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
